

537. J Acoust Soc Am. 2019 Feb;145(2):654. doi: 10.1121/1.5087827.

Deep convolutional network for animal sound classification and source attribution
using dual audio recordings.

Oikarinen T(1), Srinivasan K(1), Meisner O(1), Hyman JB(1), Parmar S(1),
Fanucci-Kiss A(1), Desimone R(1), Landman R(2), Feng G(1).

Author information: 
(1)McGovern Institute for Brain Research, Massachusetts Institute of Technology, 
43 Vassar Street, Cambridge, Massachusetts 02139, USA.
(2)Stanley Center, Broad Institute, 57 Ames Street, Cambridge, Massachusetts
02139, USA.

Erratum in
    J Acoust Soc Am. 2019 Apr;145(4):2209.

This paper introduces an end-to-end feedforward convolutional neural network that
is able to reliably classify the source and type of animal calls in a noisy
environment using two streams of audio data after being trained on a dataset of
modest size and imperfect labels. The data consists of audio recordings from
captive marmoset monkeys housed in pairs, with several other cages nearby. The
network in this paper can classify both the call type and which animal made it
with a single pass through a single network using raw spectrogram images as
input. The network vastly increases data analysis capacity for researchers
interested in studying marmoset vocalizations, and allows data collection in the 
home cage, in group housed animals.

DOI: 10.1121/1.5087827 
PMCID: PMC6786887
PMID: 30823820  [Indexed for MEDLINE]

