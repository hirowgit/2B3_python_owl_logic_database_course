{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.9.13 (main, Aug 29 2022, 05:50:54) \n",
      "[Clang 13.1.6 (clang-1316.0.21.2.5)]\n",
      "3.2.4\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.version)\n",
    "import spacy\n",
    "print(spacy.__version__)\n",
    "import ginza\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on package ginza:\n",
      "\n",
      "NAME\n",
      "    ginza\n",
      "\n",
      "PACKAGE CONTENTS\n",
      "    __main__\n",
      "    analyzer\n",
      "    bunsetu_recognizer\n",
      "    command_line\n",
      "    compound_splitter\n",
      "    disable_sentencizer\n",
      "    ene_ontonotes_mapper\n",
      "\n",
      "CLASSES\n",
      "    builtins.object\n",
      "        ginza.bunsetu_recognizer.BunsetuRecognizer\n",
      "        ginza.compound_splitter.CompoundSplitter\n",
      "    \n",
      "    class BunsetuRecognizer(builtins.object)\n",
      "     |  BunsetuRecognizer(nlp: spacy.language.Language, remain_bunsetu_suffix: bool = False) -> None\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __call__(self, doc: spacy.tokens.doc.Doc) -> spacy.tokens.doc.Doc\n",
      "     |      Call self as a function.\n",
      "     |  \n",
      "     |  __init__(self, nlp: spacy.language.Language, remain_bunsetu_suffix: bool = False) -> None\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  remain_bunsetu_suffix\n",
      "    \n",
      "    class CompoundSplitter(builtins.object)\n",
      "     |  CompoundSplitter(vocab, split_mode=None)\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __call__(self, doc: spacy.tokens.doc.Doc)\n",
      "     |      Call self as a function.\n",
      "     |  \n",
      "     |  __init__(self, vocab, split_mode=None)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  from_bytes(self, data, **_kwargs)\n",
      "     |  \n",
      "     |  from_disk(self, path, **_kwargs)\n",
      "     |  \n",
      "     |  to_bytes(self, **_kwargs)\n",
      "     |  \n",
      "     |  to_disk(self, path, **_kwargs)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  __dict__\n",
      "     |      dictionary for instance variables (if defined)\n",
      "     |  \n",
      "     |  __weakref__\n",
      "     |      list of weak references to the object (if defined)\n",
      "     |  \n",
      "     |  split_mode\n",
      "\n",
      "FUNCTIONS\n",
      "    ancestors(token: spacy.tokens.token.Token) -> Iterable[spacy.tokens.token.Token]\n",
      "    \n",
      "    bunsetu(element_func: Callable[[spacy.tokens.token.Token], ~T] = <function <lambda> at 0x1319bfe50>, condition_func: Callable[[spacy.tokens.token.Token], bool] = <function <lambda> at 0x1319bfee0>, join_func: Callable[[Iterable[~T]], ~U] = <function default_join_func at 0x1319bf280>) -> Callable[[spacy.tokens.token.Token], ~U]\n",
      "    \n",
      "    bunsetu_bi_label(token: spacy.tokens.token.Token)\n",
      "    \n",
      "    bunsetu_bi_labels(span: spacy.tokens.span.Span) -> List[str]\n",
      "    \n",
      "    bunsetu_head_list(span: spacy.tokens.span.Span) -> Iterable[int]\n",
      "    \n",
      "    bunsetu_head_tokens(span: spacy.tokens.span.Span) -> Iterable[spacy.tokens.token.Token]\n",
      "    \n",
      "    bunsetu_phrase_span(token: spacy.tokens.token.Token, phrase_relations: Iterable[str] = ('compound', 'nummod', 'nmod')) -> spacy.tokens.span.Span\n",
      "    \n",
      "    bunsetu_phrase_spans(span: spacy.tokens.span.Span, phrase_relations: Iterable[str] = ('compound', 'nummod', 'nmod')) -> Iterable[spacy.tokens.span.Span]\n",
      "    \n",
      "    bunsetu_position_type(token: spacy.tokens.token.Token)\n",
      "    \n",
      "    bunsetu_position_types(span: spacy.tokens.span.Span) -> List[str]\n",
      "    \n",
      "    bunsetu_span(token: spacy.tokens.token.Token) -> spacy.tokens.span.Span\n",
      "    \n",
      "    bunsetu_spans(span: spacy.tokens.span.Span) -> Iterable[spacy.tokens.span.Span]\n",
      "    \n",
      "    children(token: spacy.tokens.token.Token) -> Iterable[spacy.tokens.token.Token]\n",
      "    \n",
      "    conjuncts(token: spacy.tokens.token.Token) -> Tuple[spacy.tokens.token.Token]\n",
      "    \n",
      "    default_join_func(elements)\n",
      "    \n",
      "    dep(token: spacy.tokens.token.Token) -> int\n",
      "    \n",
      "    dep_(token: spacy.tokens.token.Token) -> str\n",
      "    \n",
      "    ent_iob(token: spacy.tokens.token.Token) -> int\n",
      "    \n",
      "    ent_iob_(token: spacy.tokens.token.Token) -> str\n",
      "    \n",
      "    ent_label_ene(token: spacy.tokens.token.Token) -> str\n",
      "    \n",
      "    ent_label_ontonotes(token: spacy.tokens.token.Token) -> str\n",
      "    \n",
      "    ent_type(token: spacy.tokens.token.Token) -> int\n",
      "    \n",
      "    ent_type_(token: spacy.tokens.token.Token) -> str\n",
      "    \n",
      "    force_using_normalized_form_as_lemma(force: bool)\n",
      "    \n",
      "    head(token: spacy.tokens.token.Token) -> spacy.tokens.token.Token\n",
      "    \n",
      "    inflection(token: spacy.tokens.token.Token) -> str\n",
      "    \n",
      "    is_bunsetu_head(token: spacy.tokens.token.Token)\n",
      "    \n",
      "    is_not_stop(token: spacy.tokens.token.Token) -> bool\n",
      "    \n",
      "    is_sent_start(token: spacy.tokens.token.Token) -> bool\n",
      "    \n",
      "    is_stop(token: spacy.tokens.token.Token) -> bool\n",
      "    \n",
      "    lefts(token: spacy.tokens.token.Token) -> Iterable[spacy.tokens.token.Token]\n",
      "    \n",
      "    lemma(token: spacy.tokens.token.Token) -> int\n",
      "    \n",
      "    lemma_(token: spacy.tokens.token.Token) -> str\n",
      "    \n",
      "    make_bunsetu_recognizer(nlp: spacy.language.Language, name: str, remain_bunsetu_suffix: bool = False)\n",
      "    \n",
      "    make_compound_splitter(nlp: spacy.language.Language, name: str, split_mode: str = None)\n",
      "    \n",
      "    make_disable_sentencizer(nlp: spacy.language.Language, name: str)\n",
      "    \n",
      "    norm(token: spacy.tokens.token.Token) -> int\n",
      "    \n",
      "    norm_(token: spacy.tokens.token.Token) -> str\n",
      "    \n",
      "    orth(token: spacy.tokens.token.Token) -> int\n",
      "    \n",
      "    orth_(token: spacy.tokens.token.Token) -> str\n",
      "    \n",
      "    phrase(element_func: Callable[[spacy.tokens.token.Token], ~T] = <function <lambda> at 0x1319c3310>, condition_func: Callable[[spacy.tokens.token.Token], bool] = <function <lambda> at 0x1319c3550>, join_func: Callable[[Iterable[~T]], ~U] = <function default_join_func at 0x1319bf280>) -> Callable[[spacy.tokens.token.Token], ~U]\n",
      "    \n",
      "    phrases(phrase_func: Callable[[spacy.tokens.token.Token], ~U] = <function _phrase at 0x1319c3af0>, condition_func: Callable[[spacy.tokens.token.Token], bool] = <function <lambda> at 0x1319c3ee0>) -> Callable[[spacy.tokens.span.Span], Iterable[~U]]\n",
      "    \n",
      "    pos(token: spacy.tokens.token.Token) -> int\n",
      "    \n",
      "    pos_(token: spacy.tokens.token.Token) -> str\n",
      "    \n",
      "    reading_form(token: spacy.tokens.token.Token, use_orth_if_none: bool) -> str\n",
      "    \n",
      "    rights(token: spacy.tokens.token.Token) -> Iterable[spacy.tokens.token.Token]\n",
      "    \n",
      "    set_split_mode(nlp: spacy.language.Language, mode: str)\n",
      "    \n",
      "    sub_phrases(phrase_func: Callable[[spacy.tokens.token.Token], ~U] = <function _phrase at 0x1319c3af0>, condition_func: Callable[[spacy.tokens.token.Token], bool] = <function <lambda> at 0x1319c3940>) -> Callable[[spacy.tokens.token.Token], Iterable[Tuple[str, ~U]]]\n",
      "    \n",
      "    sub_tokens(mode: str = 'A', sub_token_func: Callable[[spacy.lang.ja.DetailedToken], ~T] = <function <lambda> at 0x1319c5280>, join_func: Callable[[Iterable[~T]], ~U] = <function default_join_func at 0x1319bf280>) -> Callable[[spacy.tokens.token.Token], ~U]\n",
      "    \n",
      "    subtree(token: spacy.tokens.token.Token) -> Iterable[spacy.tokens.token.Token]\n",
      "    \n",
      "    tag(token: spacy.tokens.token.Token) -> int\n",
      "    \n",
      "    tag_(token: spacy.tokens.token.Token) -> str\n",
      "    \n",
      "    tag_to_pos(sub_tokens, next_token_tag)\n",
      "    \n",
      "    text(token: spacy.tokens.token.Token) -> str\n",
      "    \n",
      "    text_with_ws(token: spacy.tokens.token.Token) -> str\n",
      "    \n",
      "    token_i(token: spacy.tokens.token.Token) -> int\n",
      "    \n",
      "    traverse(traverse_func: Callable[[spacy.tokens.token.Token], Iterable[spacy.tokens.token.Token]], element_func: Callable[[spacy.tokens.token.Token], ~T] = <function <lambda> at 0x1319bf310>, condition_func: Callable[[spacy.tokens.token.Token], bool] = <function <lambda> at 0x1319bf3a0>, join_func: Callable[[Iterable[~T]], ~U] = <function <lambda> at 0x1319bf430>) -> Callable[[Union[spacy.tokens.token.Token, spacy.tokens.span.Span]], ~U]\n",
      "\n",
      "DATA\n",
      "    SEP = '+'\n",
      "    __all__ = ['make_compound_splitter', 'make_bunsetu_recognizer', 'make_...\n",
      "\n",
      "FILE\n",
      "    /usr/local/lib/python3.9/site-packages/ginza/__init__.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(ginza)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "【トークン】 バルセロナ　->　【レンマ】 バルセロナ\n",
      "【トークン】 五輪　->　【レンマ】 五輪\n",
      "【トークン】 柔道　->　【レンマ】 柔道\n",
      "【トークン】 金　->　【レンマ】 金\n",
      "【トークン】 メダリスト　->　【レンマ】 メダリスト\n",
      "【トークン】 と　->　【レンマ】 と\n",
      "【トークン】 し　->　【レンマ】 する\n",
      "【トークン】 て　->　【レンマ】 て\n",
      "【トークン】 の　->　【レンマ】 の\n",
      "【トークン】 実績　->　【レンマ】 実績\n",
      "【トークン】 を　->　【レンマ】 を\n",
      "【トークン】 引っさげ　->　【レンマ】 引っさげる\n",
      "【トークン】 、　->　【レンマ】 、\n",
      "【トークン】 2002　->　【レンマ】 2002\n",
      "【トークン】 年　->　【レンマ】 年\n",
      "【トークン】 に　->　【レンマ】 に\n",
      "【トークン】 プロ　->　【レンマ】 プロ\n",
      "【トークン】 総合　->　【レンマ】 総合\n",
      "【トークン】 格闘家　->　【レンマ】 格闘家\n",
      "【トークン】 に　->　【レンマ】 に\n",
      "【トークン】 転向　->　【レンマ】 転向\n"
     ]
    }
   ],
   "source": [
    "#トークン化，レンマ化\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load('ja_ginza_electra')\n",
    "doc = nlp('バルセロナ五輪柔道金メダリストとしての実績を引っさげ、2002年にプロ総合格闘家に転向')\n",
    "\n",
    "for token in doc:\n",
    "    print(\n",
    "       '【トークン】' ,token.text+'　->　'+ \n",
    "       '【レンマ】' ,token.lemma_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "【トークン】 バルセロナ　=　【品詞】 名詞-固有名詞-地名-一般\n",
      "【トークン】 五輪　=　【品詞】 名詞-普通名詞-一般\n",
      "【トークン】 柔道　=　【品詞】 名詞-普通名詞-一般\n",
      "【トークン】 金　=　【品詞】 接尾辞-名詞的-一般\n",
      "【トークン】 メダリスト　=　【品詞】 名詞-普通名詞-一般\n",
      "【トークン】 と　=　【品詞】 助詞-格助詞\n",
      "【トークン】 し　=　【品詞】 動詞-非自立可能\n",
      "【トークン】 て　=　【品詞】 助詞-接続助詞\n",
      "【トークン】 の　=　【品詞】 助詞-格助詞\n",
      "【トークン】 実績　=　【品詞】 名詞-普通名詞-一般\n",
      "【トークン】 を　=　【品詞】 助詞-格助詞\n",
      "【トークン】 引っさげ　=　【品詞】 動詞-一般\n",
      "【トークン】 、　=　【品詞】 補助記号-読点\n",
      "【トークン】 総合　=　【品詞】 名詞-普通名詞-サ変可能\n",
      "【トークン】 格闘家　=　【品詞】 名詞-普通名詞-一般\n",
      "【トークン】 ・　=　【品詞】 補助記号-一般\n",
      "【トークン】 吉田　=　【品詞】 名詞-固有名詞-人名-姓\n",
      "【トークン】 秀彦　=　【品詞】 名詞-固有名詞-人名-名\n",
      "【トークン】 の　=　【品詞】 助詞-格助詞\n",
      "【トークン】 引退　=　【品詞】 名詞-普通名詞-サ変可能\n",
      "【トークン】 試合　=　【品詞】 名詞-普通名詞-サ変可能\n",
      "【トークン】 興行　=　【品詞】 名詞-普通名詞-サ変可能\n",
      "【トークン】 「　=　【品詞】 補助記号-括弧開\n",
      "【トークン】 ASTRA　=　【品詞】 名詞-普通名詞-一般\n",
      "【トークン】 」　=　【品詞】 補助記号-括弧閉\n",
      "【トークン】 の　=　【品詞】 助詞-格助詞\n",
      "【トークン】 開催　=　【品詞】 名詞-普通名詞-サ変可能\n",
      "【トークン】 が　=　【品詞】 助詞-格助詞\n",
      "【トークン】 発表　=　【品詞】 名詞-普通名詞-サ変可能\n",
      "【トークン】 さ　=　【品詞】 動詞-非自立可能\n",
      "【トークン】 れ　=　【品詞】 助動詞\n",
      "【トークン】 た　=　【品詞】 助動詞\n",
      "【トークン】 。　=　【品詞】 補助記号-句点\n",
      "【トークン】 ATC　=　【品詞】 名詞-普通名詞-一般\n",
      "【トークン】 アーム　=　【品詞】 名詞-普通名詞-一般\n"
     ]
    }
   ],
   "source": [
    "#品詞解析\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load('ja_ginza_electra')\n",
    "doc = nlp('バルセロナ五輪柔道金メダリストとしての実績を引っさげ、'\n",
    "    '総合格闘家・吉田秀彦の引退試合興行「ASTRA」の開催が発表された。ATCアーム')\n",
    "\n",
    "for token in doc:\n",
    "    print(\n",
    "       '【トークン】' ,token.text+'　=　'+ \n",
    "       '【品詞】' ,token.tag_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[名詞節] これ  [ROOT(文の根)] これ  [DEPENDENCY(依存関係)] nsubj  [HEAD(主辞)] 料理\n",
      "[名詞節] 母  [ROOT(文の根)] 母  [DEPENDENCY(依存関係)] nsubj  [HEAD(主辞)] 作っ\n",
      "[名詞節] 美味しい料理  [ROOT(文の根)] 料理  [DEPENDENCY(依存関係)] ROOT  [HEAD(主辞)] 料理\n"
     ]
    }
   ],
   "source": [
    "#名詞句の依存関係\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"ja_ginza_electra\")\n",
    "doc = nlp(\"これは母が作った美味しい料理です\")\n",
    "\n",
    "for chunk in doc.noun_chunks:\n",
    "    print('[名詞節]',chunk.text, ' [ROOT(文の根)]',chunk.root.text, ' [DEPENDENCY(依存関係)]',chunk.root.dep_,\n",
    "            ' [HEAD(主辞)]',chunk.root.head.text)\n",
    "\n",
    "#タグの意味はspacy.explain('pobj')で調べることができる\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TEXT] [DEP] [HEAD TEXT] [HEAD POS] [CHILDREN]\n",
      "これ nsubj 料理 NOUN [は]\n",
      "は case これ PRON []\n",
      "母 nsubj 作っ VERB [が]\n",
      "が case 母 NOUN []\n",
      "作っ acl 料理 NOUN [母, た]\n",
      "た aux 作っ VERB []\n",
      "美味しい acl 料理 NOUN []\n",
      "料理 ROOT 料理 NOUN [これ, 作っ, 美味しい, です]\n",
      "です cop 料理 NOUN []\n"
     ]
    }
   ],
   "source": [
    "#文全体の依存関係\n",
    "#headとchildの有効グラフで全ての依存関係が示される\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load('ja_ginza_electra')\n",
    "doc = nlp(\"これは母が作った美味しい料理です\")\n",
    "\n",
    "print('[TEXT]','[DEP]','[HEAD TEXT]','[HEAD POS]','[CHILDREN]')\n",
    "for token in doc:\n",
    "    print(token.text, token.dep_, token.head.text, token.head.pos_,\n",
    "            [child for child in token.children])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"ja\" id=\"adc0678a0d8b4d9b87a890d373125cc5-0\" class=\"displacy\" width=\"1625\" height=\"487.0\" direction=\"ltr\" style=\"max-width: none; height: 487.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">これ</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PRON</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">は</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">母</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">が</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">作っ</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">た</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">AUX</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">美味しい</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1275\">料理</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1275\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"397.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1450\">です</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1450\">AUX</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-adc0678a0d8b4d9b87a890d373125cc5-0-0\" stroke-width=\"2px\" d=\"M70,352.0 C70,2.0 1275.0,2.0 1275.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-adc0678a0d8b4d9b87a890d373125cc5-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,354.0 L62,342.0 78,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-adc0678a0d8b4d9b87a890d373125cc5-0-1\" stroke-width=\"2px\" d=\"M70,352.0 C70,264.5 210.0,264.5 210.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-adc0678a0d8b4d9b87a890d373125cc5-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">case</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M210.0,354.0 L218.0,342.0 202.0,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-adc0678a0d8b4d9b87a890d373125cc5-0-2\" stroke-width=\"2px\" d=\"M420,352.0 C420,177.0 740.0,177.0 740.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-adc0678a0d8b4d9b87a890d373125cc5-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M420,354.0 L412,342.0 428,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-adc0678a0d8b4d9b87a890d373125cc5-0-3\" stroke-width=\"2px\" d=\"M420,352.0 C420,264.5 560.0,264.5 560.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-adc0678a0d8b4d9b87a890d373125cc5-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">case</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M560.0,354.0 L568.0,342.0 552.0,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-adc0678a0d8b4d9b87a890d373125cc5-0-4\" stroke-width=\"2px\" d=\"M770,352.0 C770,89.5 1270.0,89.5 1270.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-adc0678a0d8b4d9b87a890d373125cc5-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">acl</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M770,354.0 L762,342.0 778,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-adc0678a0d8b4d9b87a890d373125cc5-0-5\" stroke-width=\"2px\" d=\"M770,352.0 C770,264.5 910.0,264.5 910.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-adc0678a0d8b4d9b87a890d373125cc5-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M910.0,354.0 L918.0,342.0 902.0,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-adc0678a0d8b4d9b87a890d373125cc5-0-6\" stroke-width=\"2px\" d=\"M1120,352.0 C1120,264.5 1260.0,264.5 1260.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-adc0678a0d8b4d9b87a890d373125cc5-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">acl</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1120,354.0 L1112,342.0 1128,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-adc0678a0d8b4d9b87a890d373125cc5-0-7\" stroke-width=\"2px\" d=\"M1295,352.0 C1295,264.5 1435.0,264.5 1435.0,352.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-adc0678a0d8b4d9b87a890d373125cc5-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">cop</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1435.0,354.0 L1443.0,342.0 1427.0,342.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#依存関係の可視化\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "\n",
    "nlp = spacy.load('ja_ginza_electra')\n",
    "doc = nlp(\"これは母が作った美味しい料理です\")\n",
    "\n",
    "displacy.render(doc, style=\"dep\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(大正時代, 主人公, 竈門炭治郎, 山田太郎)\n",
      "text 大正時代 0 4 Era\n",
      "text 主人公 9 12 Position_Vocation\n",
      "text 竈門炭治郎 13 18 Person\n",
      "text 山田太郎 25 29 Person\n"
     ]
    }
   ],
   "source": [
    "#NER(固有表現抽出)\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load('ja_ginza_electra')\n",
    "doc = nlp(\"大正時代を舞台に、主人公(竈門炭治郎)とその友人(山田太郎)\")\n",
    "\n",
    "print(doc.ents) #固有表現が検出されなければ空のリストになる\n",
    "for ent in doc.ents:\n",
    "    print('text',ent.text, ent.start_char, ent.end_char, ent.label_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    A\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Ordinal_Number</span>\n",
       "</mark>\n",
       "アーム投入動作，\n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    大正時代\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Era</span>\n",
       "</mark>\n",
       "を舞台に、主人公(\n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    竈門炭治郎\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Broadcast_Program</span>\n",
       "</mark>\n",
       ")とその友人(\n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    山田太郎\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">Person</span>\n",
       "</mark>\n",
       ")</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#NERの可視化\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "\n",
    "nlp = spacy.load('ja_ginza_electra')\n",
    "doc = nlp(\"Aアーム投入動作，大正時代を舞台に、主人公(竈門炭治郎)とその友人(山田太郎)\")\n",
    "\n",
    "displacy.render(doc, style=\"ent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(15578876784678163569, 0, 2)]\n"
     ]
    }
   ],
   "source": [
    "from spacy.matcher import Matcher\n",
    "\n",
    "matcher = Matcher(nlp.vocab)\n",
    "pattern = [{\"LOWER\": \"hello\"}, {\"LOWER\": \"world\"}]\n",
    "matcher.add(\"HelloWorld\", [pattern])\n",
    "doc = nlp(\"hello world!\")\n",
    "matches = matcher(doc)\n",
    "\n",
    "print(matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "3518c76ac2e27c8eeca9f3949406b6132e0bedc92d170e6fc4ccaa4c9bfb7e2c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
