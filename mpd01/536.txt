

536. J Neurosci Res. 2019 Jul;97(7):760-771. doi: 10.1002/jnr.24399. Epub 2019 Mar 2.

c-Jun expression after cerebral hyperstimulation differs between rats and
marmosets.

Barros VN(1), Barros EMN(1), da Silva C(1), Lacerda S(2), Mello LE(1)(3).

Author information: 
(1)Department of Physiology, Escola Paulista de Medicina, Universidade Federal de
São Paulo-UNIFESP, São Paulo, Brazil.
(2)Hospital Israelita Albert Einstein, São Paulo, Brazil.
(3)D'Or Institute for Research and Education, IDOR, Rio de Janeiro, Brazil.

Immediate early genes (IEGs) are a fundamental element in the way we respond and 
adapt to a variety of stimuli. We have recently reported that IEG response, as
measured by c-Fos expression, is different between rodents and primates. Here, we
further extend this analysis by assessing the expression of c-Jun, one of the
main complements of c-Fos, under the same stimulation protocol. For this, we
investigated the immunohistochemical expression of c-Jun (and compared with that 
previously shown for c-Fos) after stimulation with pentylenetetrazol in the
cingulate gyrus, motor cortex, piriform cortex, inferior temporal cortex, and
visual cortex of rats and marmosets (Callithrix jacchus), both male and female.
Overall the immunohistochemical expression of c-Jun was more intense but remained
elevated for a shorter duration in marmosets as compared to rats. These results
are in contrast to what we had previously shown for c-Fos. Furthermore, in terms 
of the temporal profile, c-Fos and c-Jun expression occurred in a complementary
manner in rats-the peak of c-Fos expression coincided with low levels of c-jun
expression-and in a superimposed manner in marmosets-the peak of c-Fos expression
coincided with the peak of c-Jun expression. Since Fos proteins may form dimers
with Jun proteins and together control late gene expressions in the cell nucleus,
this different expression profile between primates and rodents may bear
meaningful impact for how the nervous system reacts and adapts to stimulation.

© 2019 Wiley Periodicals, Inc.

DOI: 10.1002/jnr.24399 
PMID: 30825347  [Indexed for MEDLINE]


537. J Acoust Soc Am. 2019 Feb;145(2):654. doi: 10.1121/1.5087827.

Deep convolutional network for animal sound classification and source attribution
using dual audio recordings.

Oikarinen T(1), Srinivasan K(1), Meisner O(1), Hyman JB(1), Parmar S(1),
Fanucci-Kiss A(1), Desimone R(1), Landman R(2), Feng G(1).

Author information: 
(1)McGovern Institute for Brain Research, Massachusetts Institute of Technology, 
43 Vassar Street, Cambridge, Massachusetts 02139, USA.
(2)Stanley Center, Broad Institute, 57 Ames Street, Cambridge, Massachusetts
02139, USA.

Erratum in
    J Acoust Soc Am. 2019 Apr;145(4):2209.

This paper introduces an end-to-end feedforward convolutional neural network that
is able to reliably classify the source and type of animal calls in a noisy
environment using two streams of audio data after being trained on a dataset of
modest size and imperfect labels. The data consists of audio recordings from
captive marmoset monkeys housed in pairs, with several other cages nearby. The
network in this paper can classify both the call type and which animal made it
with a single pass through a single network using raw spectrogram images as
input. The network vastly increases data analysis capacity for researchers
interested in studying marmoset vocalizations, and allows data collection in the 
home cage, in group housed animals.

DOI: 10.1121/1.5087827 
PMCID: PMC6786887
PMID: 30823820  [Indexed for MEDLINE]

