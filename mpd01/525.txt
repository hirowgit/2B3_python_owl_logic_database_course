

525. Nat Commun. 2019 Mar 21;10(1):1302. doi: 10.1038/s41467-019-09115-y.

Optimal features for auditory categorization.

Liu ST(1), Montes-Lourido P(2), Wang X(3), Sadagopan S(4)(5)(6).

Author information: 
(1)Department of Bioengineering, University of Pittsburgh, Pittsburgh, 15213, PA,
USA.
(2)Department of Neurobiology, University of Pittsburgh, Pittsburgh, 15213, PA,
USA.
(3)Department of Biomedical Engineering, Johns Hopkins University, Baltimore,
21205, MD, USA.
(4)Department of Bioengineering, University of Pittsburgh, Pittsburgh, 15213, PA,
USA. vatsun@pitt.edu.
(5)Department of Neurobiology, University of Pittsburgh, Pittsburgh, 15213, PA,
USA. vatsun@pitt.edu.
(6)Department of Otolaryngology, University of Pittsburgh, Pittsburgh, 15213, PA,
USA. vatsun@pitt.edu.

Humans and vocal animals use vocalizations to communicate with members of their
species. A necessary function of auditory perception is to generalize across the 
high variability inherent in vocalization production and classify them into
behaviorally distinct categories ('words' or 'call types'). Here, we demonstrate 
that detecting mid-level features in calls achieves production-invariant
classification. Starting from randomly chosen marmoset call features, we use a
greedy search algorithm to determine the most informative and least redundant
features necessary for call classification. High classification performance is
achieved using only 10-20 features per call type. Predictions of tuning
properties of putative feature-selective neurons accurately match some observed
auditory cortical responses. This feature-based approach also succeeds for call
categorization in other species, and for other complex classification tasks such 
as caller identification. Our results suggest that high-level neural
representations of sounds are based on task-dependent features optimized for
specific computational goals.

DOI: 10.1038/s41467-019-09115-y 
PMCID: PMC6428858
PMID: 30899018  [Indexed for MEDLINE]


526. PLoS One. 2019 Mar 20;14(3):e0213727. doi: 10.1371/journal.pone.0213727.
eCollection 2019.

Does opportunistic testing bias cognitive performance in primates? Learning from 
drop-outs.

Schubiger MN(1)(2), Kissling A(1), Burkart JM(1).

Author information: 
(1)Department of Anthropology, Evolutionary Cognition Group, University of
Zurich, Zurich, Switzerland.
(2)School of Social and Health Sciences, Division of Psychology, Abertay
University, Dundee, Scotland, United Kingdom.

Dropouts are a common issue in cognitive tests with non-human primates. One main 
reason for dropouts is that researchers often face a trade-off between obtaining 
a sufficiently large sample size and logistic restrictions, such as limited
access to testing facilities. The commonly-used opportunistic testing approach
deals with this trade-off by only testing those individuals who readily
participate and complete the cognitive tasks within a given time frame. All other
individuals are excluded from further testing and data analysis. However, it is
unknown if this approach merely excludes subjects who are not consistently
motivated to participate, or if these dropouts systematically differ in cognitive
ability. If the latter holds, the selection bias resulting from opportunistic
testing would systematically affect performance scores and thus comparisons
between individuals and species. We assessed the potential effects of
opportunistic testing on cognitive performance in common marmosets (Callithrix
jacchus) and squirrel monkeys (Saimiri sciureus) with a test battery consisting
of six cognitive tests: two inhibition tasks (Detour Reaching and A-not-B), one
cognitive flexibility task (Reversal Learning), one quantity discrimination task,
and two memory tasks. Importantly, we used a full testing approach in which
subjects were given as much time as they required to complete each task. For each
task, we then compared the performance of subjects who completed the task within 
the expected number of testing days with those subjects who needed more testing
time. We found that the two groups did not differ in task performance, and
therefore opportunistic testing would have been justified without risking biased 
results. If our findings generalise to other species, maximising sample sizes by 
only testing consistently motivated subjects will be a valid alternative whenever
full testing is not feasible.

DOI: 10.1371/journal.pone.0213727 
PMCID: PMC6426242
PMID: 30893340  [Indexed for MEDLINE]

Conflict of interest statement: The authors have declared that no competing
interests exist.

