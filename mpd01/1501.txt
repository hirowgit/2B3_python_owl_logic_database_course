

1501. Annu Int Conf IEEE Eng Med Biol Soc. 2013;2013:5402-5. doi:
10.1109/EMBC.2013.6610770.

A new method of concurrently visualizing states, values, and actions in
reinforcement based brain machine interfaces.

Bae J, Sanchez Giraldo LG, Pohlmeyer EA, Sanchez JC, Principe JC.

This paper presents the first attempt to quantify the individual performance of
the subject and of the computer agent on a closed loop Reinforcement Learning
Brain Machine Interface (RLBMI). The distinctive feature of the RLBMI
architecture is the co-adaptation of two systems (a BMI decoder in agent and a
BMI user in environment). In this work, an agent implemented using Q-learning via
kernel temporal difference (KTD)(Î») decodes the neural states of a monkey and
transforms them into action directions of a robotic arm. We analyze how each
participant influences the overall performance both in successful and missed
trials by visualizing states, corresponding action value Q, and resulting actions
in two-dimensional space. With the proposed methodology, we can observe how the
decoder effectively learns a good state to action mapping, and how neural states 
affect the prediction performance.

DOI: 10.1109/EMBC.2013.6610770 
PMID: 24110957  [Indexed for MEDLINE]


1502. Annu Int Conf IEEE Eng Med Biol Soc. 2013;2013:5250-3. doi:
10.1109/EMBC.2013.6610733.

Feature extraction and unsupervised classification of neural population reward
signals for reinforcement based BMI.

Prins NW, Geng S, Pohlmeyer EA, Mahmoudi B, Sanchez JC.

New reinforcement based paradigms for building adaptive decoders for
Brain-Machine Interfaces involve using feedback directly from the brain. In this 
work, we investigated neuromodulation in the Nucleus Accumbens (reward center)
during a multi-target reaching task and investigated how to extract a reinforcing
or non-reinforcing signal that could be used to adapt a BMI decoder. One of the
challenges in brain-driven adaptation is how to translate biological
neuromodulation into a single binary signal from the distributed representation
of the neural population, which may encode many aspects of reward. To extract
these signals, feature analysis and clustering were used to identify timing and
coding properties of a user's neuromodulation related to reward perception.
First, Principal Component Analysis (PCA) of reward related neural signals was
used to extract variance in the firing and the optimum time correlation between
the neural signal and the reward phase of the task. Next, k-means clustering was 
used to separate data into two classes.

DOI: 10.1109/EMBC.2013.6610733 
PMID: 24110920  [Indexed for MEDLINE]

